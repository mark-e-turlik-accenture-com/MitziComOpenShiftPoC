########################################
### Pre-OpenShift Installation command
########################################
Enter the Cluster GUID: 
#####################################################
### Save a copy of the original Ansible hosts file
#####################################################
cp /etc/ansible/hosts /etc/ansible/hosts.ORIG

##############################################################
### Add GUID environment variable to all host .bashrc files
##############################################################
ansible localhost,all -m shell -a 'export GUID=7424; echo "export GUID=7424" >> /root/.bashrc'
localhost | SUCCESS | rc=0 >>

master2.7424.internal | SUCCESS | rc=0 >>

loadbalancer1.7424.internal | SUCCESS | rc=0 >>

master1.7424.internal | SUCCESS | rc=0 >>

master3.7424.internal | SUCCESS | rc=0 >>

infranode1.7424.internal | SUCCESS | rc=0 >>

infranode2.7424.internal | SUCCESS | rc=0 >>

node1.7424.internal | SUCCESS | rc=0 >>

node2.7424.internal | SUCCESS | rc=0 >>

node3.7424.internal | SUCCESS | rc=0 >>

node4.7424.internal | SUCCESS | rc=0 >>

support1.7424.internal | SUCCESS | rc=0 >>


#############################################################
### Replace the entered GUID within the ODE hosts template
#############################################################
sed -i "s/GUID/7424/g" /etc/ansible/hosts

##################################################################
###  Run the ansible prerequisite and deploy-cluster play-books
##################################################################
ansible-playbook -f 20 /usr/share/ansible/openshift-ansible/playbooks/prerequisites.yml
ansible-playbook -f 20 /usr/share/ansible/openshift-ansible/playbooks/deploy_cluster.yml


#########################################
### Post-OpenShift Installation command
#########################################

############################################
### Verify Docker is running on all nodes
############################################
master1.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:35 UTC; 12min ago
master3.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:35 UTC; 12min ago
master2.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:34 UTC; 12min ago
infranode2.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:34 UTC; 12min ago
infranode1.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:34 UTC; 12min ago
node1.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:35 UTC; 12min ago
node2.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:35 UTC; 12min ago
node3.7424.internal | SUCCESS | rc=0 >>
   Active: active (running) since Thu 2018-08-02 02:57:35 UTC; 12min ago

###################################################################################
### Copy the .kube directory to allow system:admin access from the bastion host
###################################################################################
master1.7424.internal | SUCCESS => {
    "changed": true, 
    "checksum": "186427973270d2b74d04f1ac79e0e371a78f103f", 
    "dest": "/root/.kube/config", 
    "failed": false, 
    "md5sum": "7e0a5f33fc66873e13988c1a1ef095fd", 
    "remote_checksum": "186427973270d2b74d04f1ac79e0e371a78f103f", 
    "remote_md5sum": null
}

###############################################
### Give the admin user cluster-admin access
###############################################
cluster role "cluster-admin" added: "admin"

####################################################
### Verify that the environment is functioning ...
####################################################
NAME                       STATUS    ROLES     AGE       VERSION             LABELS
infranode1.7424.internal   Ready     <none>    10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cluster=7424,env=infra,kubernetes.io/hostname=infranode1.7424.internal,logging-infra-fluentd=true
infranode2.7424.internal   Ready     <none>    10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cluster=7424,env=infra,kubernetes.io/hostname=infranode2.7424.internal,logging-infra-fluentd=true
master1.7424.internal      Ready     master    10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cluster=7424,env=master,kubernetes.io/hostname=master1.7424.internal,logging-infra-fluentd=true,node-role.kubernetes.io/master=true
master2.7424.internal      Ready     master    10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cluster=7424,env=master,kubernetes.io/hostname=master2.7424.internal,logging-infra-fluentd=true,node-role.kubernetes.io/master=true
master3.7424.internal      Ready     master    10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cluster=7424,env=master,kubernetes.io/hostname=master3.7424.internal,logging-infra-fluentd=true,node-role.kubernetes.io/master=true
node1.7424.internal        Ready     compute   10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,client=alpha,cluster=7424,kubernetes.io/hostname=node1.7424.internal,logging-infra-fluentd=true,node-role.kubernetes.io/compute=true
node2.7424.internal        Ready     compute   10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,client=beta,cluster=7424,kubernetes.io/hostname=node2.7424.internal,logging-infra-fluentd=true,node-role.kubernetes.io/compute=true
node3.7424.internal        Ready     compute   10m       v1.9.1+a0ce1bc657   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,client=common,cluster=7424,kubernetes.io/hostname=node3.7424.internal,logging-infra-fluentd=true,node-role.kubernetes.io/compute=true
NAMESPACE                           NAME                                      READY     STATUS              RESTARTS   AGE       IP              NODE
default                             docker-registry-1-qq69m                   1/1       Running             0          8m        10.130.0.4      infranode1.7424.internal
default                             registry-console-1-j2hk5                  1/1       Running             0          7m        10.131.2.75     node3.7424.internal
default                             router-1-4wfzd                            1/1       Running             0          9m        192.199.0.52    infranode1.7424.internal
default                             router-1-wgvw6                            1/1       Running             0          9m        192.199.0.140   infranode2.7424.internal
kube-service-catalog                apiserver-9dpgt                           1/1       Running             0          51s       10.129.0.12     master1.7424.internal
kube-service-catalog                apiserver-gq4sg                           0/1       ContainerCreating   0          51s       <none>          master2.7424.internal
kube-service-catalog                apiserver-zgrj5                           1/1       Running             0          51s       10.128.0.4      master3.7424.internal
kube-service-catalog                controller-manager-j5mp9                  1/1       Running             0          45s       10.128.0.5      master3.7424.internal
kube-service-catalog                controller-manager-mrc6w                  1/1       Running             0          45s       10.129.0.13     master1.7424.internal
kube-service-catalog                controller-manager-wbrg7                  0/1       ContainerCreating   0          45s       <none>          master2.7424.internal
logging                             logging-curator-1-vrz76                   1/1       Running             0          3m        10.130.0.14     infranode1.7424.internal
logging                             logging-es-data-master-34qcbby9-1-fngcm   2/2       Running             0          2m        10.130.0.16     infranode1.7424.internal
logging                             logging-fluentd-4676l                     1/1       Running             0          2m        10.130.0.15     infranode1.7424.internal
logging                             logging-fluentd-56gg6                     1/1       Running             0          2m        10.129.2.8      infranode2.7424.internal
logging                             logging-fluentd-7gn92                     1/1       Running             0          2m        10.130.2.4      node2.7424.internal
logging                             logging-fluentd-dpnq7                     1/1       Running             0          2m        10.128.2.2      node1.7424.internal
logging                             logging-fluentd-fgwtg                     1/1       Running             0          2m        10.131.2.76     node3.7424.internal
logging                             logging-fluentd-vbw6x                     1/1       Running             0          2m        10.131.0.4      master2.7424.internal
logging                             logging-fluentd-wcm7k                     1/1       Running             0          2m        10.128.0.3      master3.7424.internal
logging                             logging-fluentd-zt2r2                     1/1       Running             0          2m        10.129.0.11     master1.7424.internal
logging                             logging-kibana-1-pxq2g                    2/2       Running             0          3m        10.130.0.13     infranode1.7424.internal
openshift-infra                     hawkular-cassandra-1-cg2wb                1/1       Running             0          5m        10.130.0.12     infranode1.7424.internal
openshift-infra                     hawkular-metrics-bmfzg                    1/1       Running             0          5m        10.129.2.4      infranode2.7424.internal
openshift-infra                     heapster-dvjh9                            1/1       Running             0          5m        10.129.2.5      infranode2.7424.internal
openshift-metrics                   prometheus-0                              6/6       Running             0          1m        10.129.2.10     infranode2.7424.internal
openshift-metrics                   prometheus-node-exporter-47lnz            1/1       Running             0          1m        192.199.0.213   master3.7424.internal
openshift-metrics                   prometheus-node-exporter-4w6n6            1/1       Running             0          1m        192.199.0.140   infranode2.7424.internal
openshift-metrics                   prometheus-node-exporter-7lkss            1/1       Running             0          1m        192.199.0.96    node1.7424.internal
openshift-metrics                   prometheus-node-exporter-9h7b2            1/1       Running             0          1m        192.199.0.52    infranode1.7424.internal
openshift-metrics                   prometheus-node-exporter-p22rp            1/1       Running             0          1m        192.199.0.159   master1.7424.internal
openshift-metrics                   prometheus-node-exporter-qsj5q            1/1       Running             0          1m        192.199.0.104   master2.7424.internal
openshift-metrics                   prometheus-node-exporter-wj7kf            1/1       Running             0          1m        192.199.0.121   node2.7424.internal
openshift-metrics                   prometheus-node-exporter-zhlxp            1/1       Running             0          1m        192.199.0.9     node3.7424.internal
openshift-template-service-broker   apiserver-46rgz                           1/1       Running             0          24s       10.129.2.11     infranode2.7424.internal
openshift-template-service-broker   apiserver-6bzq8                           1/1       Running             0          24s       10.130.0.17     infranode1.7424.internal
openshift-web-console               webconsole-84dd4bcb4d-69nhh               1/1       Running             2          7m        10.129.0.10     master1.7424.internal
openshift-web-console               webconsole-84dd4bcb4d-cqdbl               1/1       Running             2          7m        10.131.0.3      master2.7424.internal
openshift-web-console               webconsole-84dd4bcb4d-qttjn               1/1       Running             2          7m        10.128.0.2      master3.7424.internal

#############################################
### Create 10Gi and 5Gi persistent volumes
#############################################

PLAY [Transfer and execute script to create pv on nfs server] ********************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************
ok: [support1.7424.internal]

TASK [Execute the script] ********************************************************************************************************************
changed: [support1.7424.internal]

PLAY RECAP ***********************************************************************************************************************************
support1.7424.internal     : ok=2    changed=1    unreachable=0    failed=0   

Created def file for pv1
Created def file for pv2
Created def file for pv3
Created def file for pv4
Created def file for pv5
Created def file for pv6
Created def file for pv7
Created def file for pv8
Created def file for pv9
Created def file for pv10
Created def file for pv11
Created def file for pv12
Created def file for pv13
Created def file for pv14
Created def file for pv15
Created def file for pv16
Created def file for pv17
Created def file for pv18
Created def file for pv19
Created def file for pv20
Created def file for pv21
Created def file for pv22
Created def file for pv23
Created def file for pv24
Created def file for pv25
Created def file for pv26
Created def file for pv27
Created def file for pv28
Created def file for pv29
Created def file for pv30
Created def file for pv31
Created def file for pv32
Created def file for pv33
Created def file for pv34
Created def file for pv35
Created def file for pv36
Created def file for pv37
Created def file for pv38
Created def file for pv39
Created def file for pv40
Created def file for pv41
Created def file for pv42
Created def file for pv43
Created def file for pv44
Created def file for pv45
Created def file for pv46
Created def file for pv47
Created def file for pv48
Created def file for pv49
Created def file for pv50
persistentvolume "pv1" created
persistentvolume "pv10" created
persistentvolume "pv11" created
persistentvolume "pv12" created
persistentvolume "pv13" created
persistentvolume "pv14" created
persistentvolume "pv15" created
persistentvolume "pv16" created
persistentvolume "pv17" created
persistentvolume "pv18" created
persistentvolume "pv19" created
persistentvolume "pv2" created
persistentvolume "pv20" created
persistentvolume "pv21" created
persistentvolume "pv22" created
persistentvolume "pv23" created
persistentvolume "pv24" created
persistentvolume "pv25" created
persistentvolume "pv26" created
persistentvolume "pv27" created
persistentvolume "pv28" created
persistentvolume "pv29" created
persistentvolume "pv3" created
persistentvolume "pv30" created
persistentvolume "pv31" created
persistentvolume "pv32" created
persistentvolume "pv33" created
persistentvolume "pv34" created
persistentvolume "pv35" created
persistentvolume "pv36" created
persistentvolume "pv37" created
persistentvolume "pv38" created
persistentvolume "pv39" created
persistentvolume "pv4" created
persistentvolume "pv40" created
persistentvolume "pv41" created
persistentvolume "pv42" created
persistentvolume "pv43" created
persistentvolume "pv44" created
persistentvolume "pv45" created
persistentvolume "pv46" created
persistentvolume "pv47" created
persistentvolume "pv48" created
persistentvolume "pv49" created
persistentvolume "pv5" created
persistentvolume "pv50" created
persistentvolume "pv6" created
persistentvolume "pv7" created
persistentvolume "pv8" created
persistentvolume "pv9" created
master3.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Verifying Checksum
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
infranode2.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Verifying Checksum
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
master1.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
master2.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Verifying Checksum
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
infranode1.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Verifying Checksum
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
node2.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Verifying Checksum
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
node1.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Verifying Checksum
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
node3.7424.internal | SUCCESS | rc=0 >>
Trying to pull repository registry.access.redhat.com/openshift3/ose-recycler ... 
latest: Pulling from registry.access.redhat.com/openshift3/ose-recycler
d02c3bd49e78: Already exists
475b0168c252: Already exists
3b2bf31b80ed: Pulling fs layer
54b0b82cf1a3: Pulling fs layer
75ddc17ac3c3: Pulling fs layer
75ddc17ac3c3: Verifying Checksum
75ddc17ac3c3: Download complete
3b2bf31b80ed: Verifying Checksum
3b2bf31b80ed: Download complete
3b2bf31b80ed: Pull complete
54b0b82cf1a3: Verifying Checksum
54b0b82cf1a3: Download complete
54b0b82cf1a3: Pull complete
75ddc17ac3c3: Pull complete
Digest: sha256:17d42a488183e534ac477c9faad60e2250877800a80347f9d1e48fdd226e25ef
Status: Downloaded newer image for registry.access.redhat.com/openshift3/ose-recycler:latest
master1.7424.internal | SUCCESS | rc=0 >>

master3.7424.internal | SUCCESS | rc=0 >>

infranode1.7424.internal | SUCCESS | rc=0 >>

infranode2.7424.internal | SUCCESS | rc=0 >>

master2.7424.internal | SUCCESS | rc=0 >>

node2.7424.internal | SUCCESS | rc=0 >>

node3.7424.internal | SUCCESS | rc=0 >>

node1.7424.internal | SUCCESS | rc=0 >>

#######################################################################
### As a Smoke Test create and deploy the "nodejs-mongo-persistent"
#######################################################################
Now using project "smoke-test" on server "https://loadbalancer1.7424.internal:443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git

to build a new example application in Ruby.
--> Deploying template "openshift/nodejs-mongo-persistent" to project smoke-test

     Node.js + MongoDB
     ---------
     An example Node.js application with a MongoDB database. For more information about using this template, including OpenShift considerations, see https://github.com/openshift/nodejs-ex/blob/master/README.md.

     The following service(s) have been created in your project: nodejs-mongo-persistent, mongodb.
     
     For more information about using this template, including OpenShift considerations, see https://github.com/openshift/nodejs-ex/blob/master/README.md.

     * With parameters:
        * Name=nodejs-mongo-persistent
        * Namespace=openshift
        * Memory Limit=512Mi
        * Memory Limit (MongoDB)=512Mi
        * Volume Capacity=1Gi
        * Git Repository URL=https://github.com/openshift/nodejs-ex.git
        * Git Reference=
        * Context Directory=
        * Application Hostname=
        * GitHub Webhook Secret=sUIOqVPcd1fICLc4oDrB4TKa3VJaB2bGDw0pONEc # generated
        * Generic Webhook Secret=aEGpvRQl86Y3myT3Lb5E7iseb1X8tA5bwlUyKTV2 # generated
        * Database Service Name=mongodb
        * MongoDB Username=userFXW # generated
        * MongoDB Password=ipvhdlMYivhBf53V # generated
        * Database Name=sampledb
        * Database Administrator Password=pQxy5ehhyfeepAhe # generated
        * Custom NPM Mirror URL=

--> Creating resources ...
    secret "nodejs-mongo-persistent" created
    service "nodejs-mongo-persistent" created
    route "nodejs-mongo-persistent" created
    imagestream "nodejs-mongo-persistent" created
    buildconfig "nodejs-mongo-persistent" created
    deploymentconfig "nodejs-mongo-persistent" created
    persistentvolumeclaim "mongodb" created
    service "mongodb" created
    deploymentconfig "mongodb" created
--> Success
    Access your application via route 'nodejs-mongo-persistent-smoke-test.apps.7424.example.opentlc.com' 
    Build scheduled, use 'oc logs -f bc/nodejs-mongo-persistent' to track its progress.
    Run 'oc status' to view your app.

#########################################################################################
### Create a default projects template with limits and Network Policies set to ISOLATED
#########################################################################################
template "project-request" created

PLAY [Set the default projects template with Limits and NetworkPolicy defaults] **************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************
ok: [master1.7424.internal]

TASK [Execute the script] ********************************************************************************************************************
changed: [master1.7424.internal]

PLAY RECAP ***********************************************************************************************************************************
master1.7424.internal      : ok=2    changed=1    unreachable=0    failed=0   

####################################################################################
### Create Dev, Test and Prod projects. Deploy Jenkins app to manage deployment
### Enable Jenkins Service account to manage resources in Test and Prod projects.
####################################################################################
Now using project "pipeline-dev" on server "https://loadbalancer1.7424.internal:443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git

to build a new example application in Ruby.
Now using project "pipeline-test" on server "https://loadbalancer1.7424.internal:443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git

to build a new example application in Ruby.
Now using project "pipeline-prod" on server "https://loadbalancer1.7424.internal:443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git

to build a new example application in Ruby.
Now using project "pipeline-dev" on server "https://loadbalancer1.7424.internal:443".
--> Deploying template "openshift/jenkins-persistent" to project pipeline-dev

     Jenkins
     ---------
     Jenkins service, with persistent storage.
     
     NOTE: You must have persistent volumes available in your cluster to use this template.

     A Jenkins service has been created in your project.  Log into Jenkins with your OpenShift account.  The tutorial at https://github.com/openshift/origin/blob/master/examples/jenkins/README.md contains more information about using this template.

     * With parameters:
        * Jenkins Service Name=jenkins
        * Jenkins JNLP Service Name=jenkins-jnlp
        * Enable OAuth in Jenkins=false
        * Memory Limit=512Mi
        * Volume Capacity=1Gi
        * Jenkins ImageStream Namespace=openshift
        * Jenkins ImageStreamTag=jenkins:2

--> Creating resources ...
    route "jenkins" created
    persistentvolumeclaim "jenkins" created
    deploymentconfig "jenkins" created
    serviceaccount "jenkins" created
    rolebinding "jenkins_edit" created
    service "jenkins-jnlp" created
    service "jenkins" created
--> Success
    Access your application via route 'jenkins-pipeline-dev.apps.7424.example.opentlc.com' 
    Run 'oc status' to view your app.
role "edit" added: "system:serviceaccount:pipeline-dev:jenkins"
role "edit" added: "system:serviceaccount:pipeline-dev:jenkins"
role "system:image-puller" added: "system:serviceaccounts:pipeline-test"
role "system:image-puller" added: "system:serviceaccounts:pipeline-prod"

##############################################################################
### Create the "Cat of the Day (cotd2)" app in the "pipeline-dev" project
##############################################################################
--> Found image c4e4810 (2 weeks old) in image stream "openshift/php" under tag "7.1" for "php"

    Apache 2.4 with PHP 7.1 
    ----------------------- 
    PHP 7.1 available as container is a base platform for building and running various PHP 7.1 applications and frameworks. PHP is an HTML-embedded scripting language. PHP attempts to make it easy for developers to write dynamically generated web pages. PHP also offers built-in database integration for several commercial and non-commercial database management systems, so writing a database-enabled webpage with PHP is fairly simple. The most common use of PHP coding is probably as a replacement for CGI scripts.

    Tags: builder, php, php71, rh-php71

    * A source build using source code from https://github.com/StefanoPicozzi/cotd2 will be created
      * The resulting image will be pushed to image stream "cotd2:latest"
      * Use 'start-build' to trigger a new build
    * This image will be deployed in deployment config "cotd2"
    * Ports 8080/tcp, 8443/tcp will be load balanced by service "cotd2"
      * Other containers can access this service through the hostname "cotd2"

--> Creating resources ...
    imagestream "cotd2" created
    buildconfig "cotd2" created
    deploymentconfig "cotd2" created
    service "cotd2" created
--> Success
    Build scheduled, use 'oc logs -f bc/cotd2' to track its progress.
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose svc/cotd2' 
    Run 'oc status' to view your app.
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete
... waiting for cotd2 build to complete

#############################################
### Tag the cotd2 image the "pipeline-dev"
#############################################
Tag cotd2:testready set to cotd2@sha256:64a2d9a506fb2ca358b9b61f7c830dfd4d1468c44f4d963f5e0fd2e07bdaedbb.
Tag cotd2:prodready set to cotd2@sha256:64a2d9a506fb2ca358b9b61f7c830dfd4d1468c44f4d963f5e0fd2e07bdaedbb.

###################################
### Deploy the cotd2 app in TEST
###################################
--> Found image 505785f (10 seconds old) in image stream "pipeline-dev/cotd2" under tag "testready" for "pipeline-dev/cotd2:testready"

    docker.io/pipeline-dev/cotd2-1:fcdb0161 
    --------------------------------------- 
    PHP 7.1 available as container is a base platform for building and running various PHP 7.1 applications and frameworks. PHP is an HTML-embedded scripting language. PHP attempts to make it easy for developers to write dynamically generated web pages. PHP also offers built-in database integration for several commercial and non-commercial database management systems, so writing a database-enabled webpage with PHP is fairly simple. The most common use of PHP coding is probably as a replacement for CGI scripts.

    Tags: builder, php, php71, rh-php71

    * This image will be deployed in deployment config "cotd2"
    * Ports 8080/tcp, 8443/tcp will be load balanced by service "cotd2"
      * Other containers can access this service through the hostname "cotd2"

--> Creating resources ...
    imagestreamtag "cotd2:testready" created
    deploymentconfig "cotd2" created
    service "cotd2" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose svc/cotd2' 
    Run 'oc status' to view your app.

###################################
### Deploy the cotd2 app in PROD
###################################
--> Found image 505785f (11 seconds old) in image stream "pipeline-dev/cotd2" under tag "prodready" for "pipeline-dev/cotd2:prodready"

    docker.io/pipeline-dev/cotd2-1:fcdb0161 
    --------------------------------------- 
    PHP 7.1 available as container is a base platform for building and running various PHP 7.1 applications and frameworks. PHP is an HTML-embedded scripting language. PHP attempts to make it easy for developers to write dynamically generated web pages. PHP also offers built-in database integration for several commercial and non-commercial database management systems, so writing a database-enabled webpage with PHP is fairly simple. The most common use of PHP coding is probably as a replacement for CGI scripts.

    Tags: builder, php, php71, rh-php71

    * This image will be deployed in deployment config "cotd2"
    * Ports 8080/tcp, 8443/tcp will be load balanced by service "cotd2"
      * Other containers can access this service through the hostname "cotd2"

--> Creating resources ...
    imagestreamtag "cotd2:prodready" created
    deploymentconfig "cotd2" created
    service "cotd2" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose svc/cotd2' 
    Run 'oc status' to view your app.

########################################
### Expose the Dev, Test and Prod APPs
########################################
route "cotd2" exposed
route "cotd2" exposed
route "cotd2" exposed

##########################################
### Create the pipeline-dev build config
##########################################
buildconfig "pipeline-dev" created

##################################################
### Set up autoscaling for the cotd2 app in PROD
##################################################
deploymentconfig "cotd2" autoscaled
NAME      REFERENCE                TARGETS           MINPODS   MAXPODS   REPLICAS   AGE
cotd2     DeploymentConfig/cotd2   <unknown> / 80%   1         5         0          0s

###########################################################
### Create and assign users to the Alpha and Beta groups
###########################################################
NAME         USERS
Alpha-Corp   amy, andrew
NAME        USERS
Beta-Corp   betty, brian

###############################################################
### Create and assign policies to the Alpha and Beta projects
###############################################################
Created project alpha-project
Created project beta-project
role "admin" added: "Alpha-Corp"
role "admin" added: "Beta-Corp"

########################################################################
### Create the "nodejs-mongo-persistent" app within the Alpha projects
########################################################################
--> Deploying template "openshift/nodejs-mongo-persistent" to project alpha-project

     Node.js + MongoDB
     ---------
     An example Node.js application with a MongoDB database. For more information about using this template, including OpenShift considerations, see https://github.com/openshift/nodejs-ex/blob/master/README.md.

     The following service(s) have been created in your project: nodejs-mongo-persistent, mongodb.
     
     For more information about using this template, including OpenShift considerations, see https://github.com/openshift/nodejs-ex/blob/master/README.md.

     * With parameters:
        * Name=nodejs-mongo-persistent
        * Namespace=openshift
        * Memory Limit=512Mi
        * Memory Limit (MongoDB)=512Mi
        * Volume Capacity=1Gi
        * Git Repository URL=https://github.com/openshift/nodejs-ex.git
        * Git Reference=
        * Context Directory=
        * Application Hostname=
        * GitHub Webhook Secret=2DwSJUPBiFcfvqQyBdjlNqLpK5IAsjer1o4Ur51w # generated
        * Generic Webhook Secret=X0tspotRh06f5xS8MxNt8qnAtCFOH7sgEE1hQBiq # generated
        * Database Service Name=mongodb
        * MongoDB Username=userJ4F # generated
        * MongoDB Password=1dAdOXk8LrOPqCIk # generated
        * Database Name=sampledb
        * Database Administrator Password=dNy1qlWnVMjvjkPK # generated
        * Custom NPM Mirror URL=

--> Creating resources ...
    secret "nodejs-mongo-persistent" created
    service "nodejs-mongo-persistent" created
    route "nodejs-mongo-persistent" created
    imagestream "nodejs-mongo-persistent" created
    buildconfig "nodejs-mongo-persistent" created
    deploymentconfig "nodejs-mongo-persistent" created
    persistentvolumeclaim "mongodb" created
    service "mongodb" created
    deploymentconfig "mongodb" created
--> Success
    Access your application via route 'nodejs-mongo-persistent-alpha-project.apps.7424.example.opentlc.com' 
    Build scheduled, use 'oc logs -f bc/nodejs-mongo-persistent' to track its progress.
    Run 'oc status' to view your app.

########################################################################
### Create the "nodejs-mongo-persistent" app within the Beta projects
########################################################################
--> Deploying template "openshift/nodejs-mongo-persistent" to project beta-project

     Node.js + MongoDB
     ---------
     An example Node.js application with a MongoDB database. For more information about using this template, including OpenShift considerations, see https://github.com/openshift/nodejs-ex/blob/master/README.md.

     The following service(s) have been created in your project: nodejs-mongo-persistent, mongodb.
     
     For more information about using this template, including OpenShift considerations, see https://github.com/openshift/nodejs-ex/blob/master/README.md.

     * With parameters:
        * Name=nodejs-mongo-persistent
        * Namespace=openshift
        * Memory Limit=512Mi
        * Memory Limit (MongoDB)=512Mi
        * Volume Capacity=1Gi
        * Git Repository URL=https://github.com/openshift/nodejs-ex.git
        * Git Reference=
        * Context Directory=
        * Application Hostname=
        * GitHub Webhook Secret=eDkHwRhiP0b1vUTBiRJPBxtBfBnisrhHGuu8jly3 # generated
        * Generic Webhook Secret=uGLdRgIO3E76lSGQNC4MvRUo4xQYGFvvJ3kICy2u # generated
        * Database Service Name=mongodb
        * MongoDB Username=userIPB # generated
        * MongoDB Password=kGFwYTBN2Jc56QEa # generated
        * Database Name=sampledb
        * Database Administrator Password=bI7j4P2nfupjXAKu # generated
        * Custom NPM Mirror URL=

--> Creating resources ...
    secret "nodejs-mongo-persistent" created
    service "nodejs-mongo-persistent" created
    route "nodejs-mongo-persistent" created
    imagestream "nodejs-mongo-persistent" created
    buildconfig "nodejs-mongo-persistent" created
    deploymentconfig "nodejs-mongo-persistent" created
    persistentvolumeclaim "mongodb" created
    service "mongodb" created
    deploymentconfig "mongodb" created
--> Success
    Access your application via route 'nodejs-mongo-persistent-beta-project.apps.7424.example.opentlc.com' 
    Build scheduled, use 'oc logs -f bc/nodejs-mongo-persistent' to track its progress.
    Run 'oc status' to view your app.
